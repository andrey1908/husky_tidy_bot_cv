{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from estimate_object_pose import BoxSegmentation, BoxPoseEstimation\n",
    "from realsense_camera import RealsenseCamera\n",
    "from camera_utils import stream\n",
    "from copy import deepcopy\n",
    "from time import time, sleep\n",
    "from aruco import detect_aruco\n",
    "\n",
    "def show(image):\n",
    "    cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "\n",
    "camera = RealsenseCamera(enable_depth=True)\n",
    "\n",
    "K = camera.K\n",
    "D = camera.D\n",
    "depth_scale = camera.depth_scale\n",
    "\n",
    "# box = \"white\"\n",
    "box = \"green\"\n",
    "# box = \"red\"\n",
    "assert box in (\"white\", \"green\", \"red\")\n",
    "\n",
    "if box == \"white\":\n",
    "    edges_sizes = np.array([0.11, 0.05, 0.022])\n",
    "if box == \"green\":\n",
    "    edges_sizes = np.array([0.159, 0.079, 0.030])\n",
    "if box == \"red\":\n",
    "    edges_sizes = np.array([0.079, 0.079, 0.079])\n",
    "\n",
    "box_segmentation = BoxSegmentation(erosion_size=0)\n",
    "box_pose_estimation = BoxPoseEstimation(\n",
    "    edges_sizes=edges_sizes, edge_points_per_cm=7,\n",
    "    voxel_size=0.005, depth_scale=depth_scale, K=K, D=D,\n",
    "    global_max_correspondence_distance=0.04,\n",
    "    max_correspondence_distances=[0.04, 0.029, 0.018, 0.007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test box segmentation\n",
    "\n",
    "camera.start()\n",
    "stream(camera)  # waits for a key to get image\n",
    "image = camera.read()\n",
    "camera.stop()\n",
    "\n",
    "mask = box_segmentation.segment_box(image, box)\n",
    "masked_image = image.copy()\n",
    "masked_image[mask == 0] = 0\n",
    "show(masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate box pose\n",
    "\n",
    "camera.start()\n",
    "stream(camera)  # waits for a key to get image\n",
    "image, depth = camera.read(read_color=True, read_depth=True)\n",
    "camera.stop()\n",
    "\n",
    "mask = box_segmentation.segment_box(image, box)\n",
    "box_pose = box_pose_estimation.estimate_pose(mask, depth)\n",
    "if box_pose is None:\n",
    "    print(f\"Could not estimate pose. Reason: {box_pose_estimation.reason}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize point clouds\n",
    "\n",
    "transformed_box_pc = deepcopy(box_pose_estimation.gt_pc)\n",
    "transformed_box_pc.transform(box_pose)\n",
    "transformed_box_pc.paint_uniform_color(np.array([1, 0, 0]))\n",
    "extracted_box_pc = box_pose_estimation.extracted_pc\n",
    "extracted_box_pc.paint_uniform_color(np.array([0, 1, 0]))\n",
    "o3d.visualization.draw_geometries([transformed_box_pc, extracted_box_pc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize point clouds down\n",
    "\n",
    "transformed_box_pc_down = deepcopy(box_pose_estimation.gt_pc_down)\n",
    "transformed_box_pc_down.transform(box_pose)\n",
    "transformed_box_pc_down.paint_uniform_color(np.array([1, 0, 0]))\n",
    "extracted_box_pc_down = box_pose_estimation.extracted_pc_down\n",
    "extracted_box_pc_down.paint_uniform_color(np.array([0, 1, 0]))\n",
    "o3d.visualization.draw_geometries([transformed_box_pc_down, extracted_box_pc_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize box frame\n",
    "\n",
    "force_z_axis_up = False\n",
    "if force_z_axis_up:\n",
    "    if box_pose[1, 2] > 0:\n",
    "        correction = np.eye(4)\n",
    "        correction[0:3, 0:3], _ = cv2.Rodrigues(np.array([np.pi, 0., 0.]))\n",
    "        pose = np.matmul(box_pose, correction)\n",
    "else:\n",
    "    pose = box_pose\n",
    "\n",
    "draw = image.copy()\n",
    "rvec, _ = cv2.Rodrigues(pose[0:3, 0:3])\n",
    "tvec = box_pose[0:3, 3]\n",
    "cv2.drawFrameAxes(draw, K, D, rvec, tvec, 0.07)\n",
    "show(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream depth\n",
    "\n",
    "def draw_depth(key, image, depth):\n",
    "    depth_cm = (depth * depth_scale * 100).clip(0, 255).astype(np.uint8)\n",
    "    image[...] = np.tile(depth_cm, (3, 1, 1)).transpose(1, 2, 0)\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=draw_depth)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream box segmentation\n",
    "\n",
    "def segment_box(key, image, **kwargs):\n",
    "    mask = box_segmentation.segment_box(image, box)\n",
    "    image[mask == 0] //= 5\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=segment_box)\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream box frame\n",
    "\n",
    "times = list()\n",
    "\n",
    "def draw_box_frame(key, image, depth):\n",
    "    tic = time()\n",
    "    mask = box_segmentation.segment_box(image, box)\n",
    "    box_pose = box_pose_estimation.estimate_pose(mask, depth)\n",
    "    toc = time()\n",
    "\n",
    "    if box_pose is None:\n",
    "        return\n",
    "\n",
    "    if box_pose[1, 2] > 0:\n",
    "        correction = np.eye(4)\n",
    "        correction[0:3, 0:3], _ = cv2.Rodrigues(np.array([np.pi, 0., 0.]))\n",
    "        box_pose = np.matmul(box_pose, correction)\n",
    "\n",
    "    rvec, _ = cv2.Rodrigues(box_pose[0:3, 0:3])\n",
    "    tvec = box_pose[0:3, 3]\n",
    "    cv2.drawFrameAxes(image, K, D, rvec, tvec, 0.07)\n",
    "\n",
    "    times.append(toc - tic)\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=draw_box_frame)\n",
    "camera.stop()\n",
    "\n",
    "print(f\"{(sum(times) / len(times) * 1000):.1f} ms\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug box frame\n",
    "\n",
    "max_n = 100\n",
    "images = list()\n",
    "depths = list()\n",
    "draws = list()\n",
    "\n",
    "times = list()\n",
    "\n",
    "def draw_box_frame(key, image, depth):\n",
    "    images.append(image.copy())\n",
    "    depths.append(depth.copy())\n",
    "\n",
    "    tic = time()\n",
    "    mask = box_segmentation.segment_box(image, box)\n",
    "    box_pose = box_pose_estimation.estimate_pose(mask, depth)\n",
    "    toc = time()\n",
    "\n",
    "    if box_pose is None:\n",
    "        draws.append(image.copy())\n",
    "        if len(images) > max_n:\n",
    "            images.pop(0)\n",
    "            depths.pop(0)\n",
    "            draws.pop(0)\n",
    "        return\n",
    "\n",
    "    if box_pose[1, 2] > 0:\n",
    "        correction = np.eye(4)\n",
    "        correction[0:3, 0:3], _ = cv2.Rodrigues(np.array([np.pi, 0., 0.]))\n",
    "        box_pose = np.matmul(box_pose, correction)\n",
    "\n",
    "    rvec, _ = cv2.Rodrigues(box_pose[0:3, 0:3])\n",
    "    tvec = box_pose[0:3, 3]\n",
    "    cv2.drawFrameAxes(image, K, D, rvec, tvec, 0.07)\n",
    "\n",
    "    times.append(toc - tic)\n",
    "\n",
    "    draws.append(image.copy())\n",
    "\n",
    "    if len(images) > max_n:\n",
    "        images.pop(0)\n",
    "        depths.pop(0)\n",
    "        draws.pop(0)\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=draw_box_frame)\n",
    "camera.stop()\n",
    "\n",
    "print(f\"{(sum(times) / len(times) * 1000):.1f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, depth, draw) in enumerate(zip(images, depths, draws)):\n",
    "    print(i)\n",
    "    show(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "show(draws[i])\n",
    "image = images[i]\n",
    "depth = depths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream point clouds\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "extracted_pc = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(extracted_pc)\n",
    "\n",
    "gt_pc = deepcopy(box_pose_estimation.gt_pc)\n",
    "gt_pc.paint_uniform_color(np.array([1, 0, 0]))\n",
    "vis.add_geometry(gt_pc)\n",
    "\n",
    "n_accum = 5\n",
    "box_poses = list()\n",
    "rvecs = list()\n",
    "tvecs = list()\n",
    "\n",
    "def show_point_cloud(key, image, depth):\n",
    "    mask = box_segmentation.segment_box(image, box)\n",
    "    box_pose = box_pose_estimation.estimate_pose(mask, depth)\n",
    "    if box_pose is None:\n",
    "        extracted_pc.points.clear()\n",
    "        gt_pc.points.clear()\n",
    "    else:\n",
    "        if len(box_poses) > 0:\n",
    "            box_pose = BoxPoseEstimation.align_box_poses(box_poses[-1], box_pose)\n",
    "        rvec, _ = cv2.Rodrigues(box_pose[:3, :3])\n",
    "        tvec = box_pose[:3, 3]\n",
    "        box_poses.append(box_pose)\n",
    "        rvecs.append(rvec)\n",
    "        tvecs.append(tvec)\n",
    "        if len(box_poses) > n_accum:\n",
    "            box_poses.pop(0)\n",
    "            rvecs.pop(0)\n",
    "            tvecs.pop(0)\n",
    "\n",
    "        rvec = sum(rvecs) / len(rvecs)\n",
    "        tvec = sum(tvecs) / len(tvecs)\n",
    "        box_pose = np.eye(4)\n",
    "        box_pose[:3, :3] = cv2.Rodrigues(rvec)[0]\n",
    "        box_pose[:3, 3] = tvec\n",
    "\n",
    "        extracted_pc.points = deepcopy(box_pose_estimation.extracted_pc.points)\n",
    "        extracted_pc.paint_uniform_color(np.array([0, 1, 0]))\n",
    "        gt_pc.points = deepcopy(box_pose_estimation.gt_pc.points)\n",
    "        gt_pc.paint_uniform_color(np.array([1, 0, 0]))\n",
    "        gt_pc.transform(box_pose)\n",
    "        # extracted_pc.transform(np.linalg.inv(box_pose))\n",
    "\n",
    "    vis.update_geometry(extracted_pc)\n",
    "    vis.update_geometry(gt_pc)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=show_point_cloud)\n",
    "camera.stop()\n",
    "\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream comparison of aruco and semantic box detection\n",
    "\n",
    "assert box == \"white\"\n",
    "\n",
    "rot_errors = list()\n",
    "trans_errors = list()\n",
    "last_box_pose = None\n",
    "\n",
    "def callback(key, image, depth, **kwargs):\n",
    "    mask = box_segmentation.segment_box(image, box)\n",
    "    box_pose = box_pose_estimation.estimate_pose(mask, depth)\n",
    "    if box_pose is None:\n",
    "        return\n",
    "    if last_box_pose is not None:\n",
    "        box_pose = BoxPoseEstimation.align_box_poses(last_box_pose, box_pose)\n",
    "    last_box_pose = box_pose\n",
    "\n",
    "    arucos = detect_aruco(image, K, D, 0.029, True,\n",
    "        aruco_dict=cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_1000))\n",
    "    if arucos.n != 1:\n",
    "        return\n",
    "\n",
    "    # aruco\n",
    "    pose = arucos.get_pose(0, 0)\n",
    "    correction = np.eye(4)\n",
    "    correction[2, 3] = -0.011\n",
    "    pose = np.matmul(pose, correction)\n",
    "    aruco_rotation = cv2.Rodrigues(pose[:3, :3])[0][:, 0]\n",
    "    aruco_translation = pose[:3, 3]\n",
    "\n",
    "    # pc\n",
    "    if box_pose[1, 2] > 0:\n",
    "        correction = np.eye(4)\n",
    "        correction[0:3, 0:3], _ = cv2.Rodrigues(np.array([np.pi, 0., 0.]))\n",
    "        pose = np.matmul(box_pose, correction)\n",
    "    else:\n",
    "        pose = box_pose\n",
    "    pc_rotation = cv2.Rodrigues(pose[:3, :3])[0][:, 0]\n",
    "    pc_translation = pose[:3, 3]\n",
    "\n",
    "    rot_error = np.linalg.norm(aruco_rotation - pc_rotation) * 180 / np.pi\n",
    "    trans_error = np.linalg.norm(aruco_translation - pc_translation) * 100\n",
    "\n",
    "    rot_errors.append(rot_error)\n",
    "    trans_errors.append(trans_error)\n",
    "\n",
    "    correction = np.eye(4)\n",
    "    correction[:3, :3], _ = cv2.Rodrigues(np.array([0, np.pi, 0]))\n",
    "    correction[:3, 3] = np.array([0.11 / 2, -0.05 / 2, 0.022 / 2])\n",
    "\n",
    "    # aruco\n",
    "    pose = np.eye(4)\n",
    "    pose[:3, :3], _ = cv2.Rodrigues(aruco_rotation)\n",
    "    pose[:3, 3] = aruco_translation\n",
    "    pose = np.matmul(pose, correction)\n",
    "    rvec, _ = cv2.Rodrigues(pose[:3, :3])\n",
    "    tvec = pose[:3, 3]\n",
    "    cv2.drawFrameAxes(image, K, D, rvec, tvec, 0.10, 1)\n",
    "\n",
    "    # pc\n",
    "    pose = np.eye(4)\n",
    "    pose[:3, :3], _ = cv2.Rodrigues(pc_rotation)\n",
    "    pose[:3, 3] = pc_translation\n",
    "    pose = np.matmul(pose, correction)\n",
    "    rvec, _ = cv2.Rodrigues(pose[:3, :3])\n",
    "    tvec = pose[:3, 3]\n",
    "    cv2.drawFrameAxes(image, K, D, rvec, tvec, 0.07, 1)\n",
    "\n",
    "camera.start()\n",
    "stream(camera, callbacks=callback)\n",
    "camera.stop()\n",
    "\n",
    "print(sum(rot_errors) / len(rot_errors))\n",
    "print(max(rot_errors))\n",
    "\n",
    "print(sum(trans_errors) / len(trans_errors))\n",
    "print(max(trans_errors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
